{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Enhanced Future CCU Prediction Model (with Fortnite API)\n",
        "\n",
        "**ENHANCED APPROACH:** Predict future CCU using both fncreate.gg + Fortnite Ecosystem API!\n",
        "\n",
        "**Target:** Predict CCU 7 days from now  \n",
        "**Data Sources:**\n",
        "- fncreate.gg: Creator stats, CCU trends, discovery\n",
        "- Fortnite API: Retention, engagement, virality\n",
        "\n",
        "**NEW FEATURES:**\n",
        "- Retention rate (% players who return)\n",
        "- Session engagement (avg minutes per player)\n",
        "- Play frequency (repeat play behavior)\n",
        "- Virality score (favorites + recommendations)\n",
        "\n",
        "**Expected R¬≤:** 0.80+ (improvement from 0.76!)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Set Up Data Paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ fncreate.gg data: ../data/raw\n",
            "üìÅ Fortnite API data: ../data/fortnite_metrics\n",
            "üìÅ Model output: ../data/models\n",
            "\n",
            "üìä fncreate.gg maps: 962\n",
            "üìä Fortnite API maps: 962\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "FNCREATE_DIR = Path('../data/raw')\n",
        "FORTNITE_DIR = Path('../data/fortnite_metrics')\n",
        "MODEL_DIR = Path('../data/models')\n",
        "MODEL_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "print(f\"üìÅ fncreate.gg data: {FNCREATE_DIR}\")\n",
        "print(f\"üìÅ Fortnite API data: {FORTNITE_DIR}\")\n",
        "print(f\"üìÅ Model output: {MODEL_DIR}\")\n",
        "\n",
        "# Count files\n",
        "fncreate_files = list(FNCREATE_DIR.glob('map_*.json'))\n",
        "fortnite_files = list(FORTNITE_DIR.glob('fortnite_*.json'))\n",
        "\n",
        "print(f\"\\nüìä fncreate.gg maps: {len(fncreate_files)}\")\n",
        "print(f\"üìä Fortnite API maps: {len(fortnite_files)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Extraction Functions\n",
        "\n",
        "We'll create two functions:\n",
        "1. **extract_fncreate_features()** - Extract from fncreate.gg data (11 features)\n",
        "2. **extract_fortnite_features()** - Extract from Fortnite API data (9 NEW features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ fncreate.gg feature extractor created\n"
          ]
        }
      ],
      "source": [
        "def extract_fncreate_features(map_file):\n",
        "    \"\"\"\n",
        "    Extract features from fncreate.gg data.\n",
        "    Returns dict with 11 features + target.\n",
        "    \"\"\"\n",
        "    with open(map_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    map_data = data.get('map_data', {})\n",
        "    stats_7d_raw = data.get('stats_7d', {})\n",
        "    \n",
        "    # Extract map code\n",
        "    map_code = map_data.get('mnemonic', '')\n",
        "    \n",
        "    # Basic features\n",
        "    features = {\n",
        "        'map_code': map_code,\n",
        "        'creator_followers': map_data.get('creator', {}).get('followers', 0),\n",
        "        'in_discovery': 1 if map_data.get('discovery', False) else 0,\n",
        "        'xp_enabled': 1 if map_data.get('xpEnabled', False) else 0,\n",
        "        'num_tags': len(map_data.get('tags', [])),\n",
        "        'max_players': map_data.get('maxPlayers', 0),\n",
        "        'version': map_data.get('version', 1),\n",
        "    }\n",
        "    \n",
        "    # Time-series features from stats_7d\n",
        "    # stats_7d is a dict with structure: {\"success\": true, \"data\": {\"stats\": [...]}}\n",
        "    ccu_values = []\n",
        "    if stats_7d_raw and stats_7d_raw.get('success'):\n",
        "        stats_data = stats_7d_raw.get('data', {})\n",
        "        ccu_values = stats_data.get('stats', [])\n",
        "    \n",
        "    if ccu_values and len(ccu_values) >= 50:\n",
        "        # Split into training (first 85%) and prediction (last 15%)\n",
        "        # This ensures we're truly predicting the FUTURE\n",
        "        split_point = int(len(ccu_values) * 0.85)\n",
        "        \n",
        "        training_data = ccu_values[:split_point]  # Use first 85% for features\n",
        "        future_data = ccu_values[split_point:]    # Last 15% is \"future\"\n",
        "        \n",
        "        # Features from TRAINING data only (past)\n",
        "        features['baseline_ccu'] = np.mean(training_data)\n",
        "        \n",
        "        # Target: Average CCU in the \"future\" period\n",
        "        features['future_ccu_7d'] = np.mean(future_data)\n",
        "        \n",
        "        # Trend slope (from training data)\n",
        "        if len(training_data) > 1:\n",
        "            x = np.arange(len(training_data))\n",
        "            slope, _ = np.polyfit(x, training_data, 1)\n",
        "            features['trend_slope'] = slope\n",
        "        else:\n",
        "            features['trend_slope'] = 0\n",
        "        \n",
        "        # Recent momentum (last 20% vs first 20% of training data)\n",
        "        recent_idx = int(len(training_data) * 0.8)\n",
        "        early_idx = int(len(training_data) * 0.2)\n",
        "        recent_avg = np.mean(training_data[recent_idx:])\n",
        "        early_avg = np.mean(training_data[:early_idx])\n",
        "        features['recent_momentum'] = recent_avg - early_avg if early_avg > 0 else 0\n",
        "        \n",
        "        # Volatility (from training data)\n",
        "        features['volatility'] = np.std(training_data)\n",
        "    else:\n",
        "        features['baseline_ccu'] = 0\n",
        "        features['future_ccu_7d'] = 0\n",
        "        features['trend_slope'] = 0\n",
        "        features['recent_momentum'] = 0\n",
        "        features['volatility'] = 0\n",
        "    \n",
        "    # Map age\n",
        "    created_at = map_data.get('createdAt')\n",
        "    if created_at:\n",
        "        try:\n",
        "            created_date = datetime.fromisoformat(created_at.replace('Z', '+00:00'))\n",
        "            features['map_age_days'] = (datetime.now() - created_date).days\n",
        "        except:\n",
        "            features['map_age_days'] = 0\n",
        "    else:\n",
        "        features['map_age_days'] = 0\n",
        "    \n",
        "    return features\n",
        "\n",
        "print(\"‚úÖ fncreate.gg feature extractor created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Fortnite API feature extractor created\n"
          ]
        }
      ],
      "source": [
        "def extract_fortnite_features(fortnite_file):\n",
        "    \"\"\"\n",
        "    Extract features from Fortnite Ecosystem API data.\n",
        "    Returns dict with 9 NEW features.\n",
        "    \"\"\"\n",
        "    with open(fortnite_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # Check if data was successfully fetched\n",
        "    if data.get('status') != 'success':\n",
        "        return None\n",
        "    \n",
        "    metrics = data.get('metrics', {})\n",
        "    \n",
        "    features = {\n",
        "        'map_code': data.get('map_code', '')\n",
        "    }\n",
        "    \n",
        "    # Helper: get average value from time-series\n",
        "    def get_avg(metric_name, default=0):\n",
        "        metric_data = metrics.get(metric_name, [])\n",
        "        if metric_data:\n",
        "            values = [m.get('value', 0) for m in metric_data]\n",
        "            return np.mean(values) if values else default\n",
        "        return default\n",
        "    \n",
        "    # Helper: get latest value\n",
        "    def get_latest(metric_name, default=0):\n",
        "        metric_data = metrics.get(metric_name, [])\n",
        "        if metric_data:\n",
        "            return metric_data[-1].get('value', default)\n",
        "        return default\n",
        "    \n",
        "    # Extract features\n",
        "    features['avg_session_length'] = get_avg('averageMinutesPerPlayer', 0)\n",
        "    features['retention_rate'] = get_latest('retention', 0)\n",
        "    features['favorites_count'] = get_latest('favorites', 0)\n",
        "    features['recommendations_count'] = get_latest('recommendations', 0)\n",
        "    features['unique_players'] = get_latest('uniquePlayers', 0)\n",
        "    features['total_plays'] = get_latest('plays', 0)\n",
        "    features['total_minutes_played'] = get_latest('minutesPlayed', 0)\n",
        "    \n",
        "    # Derived features\n",
        "    # Play frequency: avg plays per player\n",
        "    if features['unique_players'] > 0:\n",
        "        features['play_frequency'] = features['total_plays'] / features['unique_players']\n",
        "    else:\n",
        "        features['play_frequency'] = 0\n",
        "    \n",
        "    # Virality score\n",
        "    features['virality_score'] = features['favorites_count'] + features['recommendations_count']\n",
        "    \n",
        "    # Engagement per player\n",
        "    if features['unique_players'] > 0:\n",
        "        features['engagement_per_player'] = features['total_minutes_played'] / features['unique_players']\n",
        "    else:\n",
        "        features['engagement_per_player'] = 0\n",
        "    \n",
        "    return features\n",
        "\n",
        "print(\"‚úÖ Fortnite API feature extractor created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load and Merge Data\n",
        "\n",
        "Now we'll loop through all maps, extract features from both sources, and merge them!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Loading and merging datasets...\n",
            "\n",
            "  Processed 100/962 maps...\n",
            "  Processed 200/962 maps...\n",
            "  Processed 300/962 maps...\n",
            "  Processed 400/962 maps...\n",
            "  Processed 500/962 maps...\n",
            "  Processed 600/962 maps...\n",
            "  Processed 700/962 maps...\n",
            "  Processed 800/962 maps...\n",
            "  Processed 900/962 maps...\n",
            "\n",
            "‚úÖ Loaded 951 maps with both datasets\n",
            "üìä Dataset shape: (951, 23)\n",
            "\n",
            "üìã Columns (23): map_code, creator_followers, in_discovery, xp_enabled, num_tags, max_players, version, baseline_ccu, future_ccu_7d, trend_slope, recent_momentum, volatility, map_age_days, avg_session_length, retention_rate, favorites_count, recommendations_count, unique_players, total_plays, total_minutes_played, play_frequency, virality_score, engagement_per_player\n"
          ]
        }
      ],
      "source": [
        "print(\"üîÑ Loading and merging datasets...\\n\")\n",
        "\n",
        "all_features = []\n",
        "\n",
        "for i, fncreate_file in enumerate(fncreate_files, 1):\n",
        "    if i % 100 == 0:\n",
        "        print(f\"  Processed {i}/{len(fncreate_files)} maps...\")\n",
        "    \n",
        "    # Get corresponding Fortnite file\n",
        "    # map_8530_0110_2817.json -> fortnite_8530_0110_2817.json\n",
        "    fortnite_filename = fncreate_file.name.replace('map_', 'fortnite_')\n",
        "    fortnite_file = FORTNITE_DIR / fortnite_filename\n",
        "    \n",
        "    # Extract fncreate features\n",
        "    try:\n",
        "        fncreate_feat = extract_fncreate_features(fncreate_file)\n",
        "    except:\n",
        "        continue\n",
        "    \n",
        "    # Extract Fortnite features (if available)\n",
        "    if fortnite_file.exists():\n",
        "        try:\n",
        "            fortnite_feat = extract_fortnite_features(fortnite_file)\n",
        "            if fortnite_feat:\n",
        "                # Merge both feature sets\n",
        "                merged = {**fncreate_feat, **fortnite_feat}\n",
        "                all_features.append(merged)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "print(f\"\\n‚úÖ Loaded {len(all_features)} maps with both datasets\")\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(all_features)\n",
        "print(f\"üìä Dataset shape: {df.shape}\")\n",
        "print(f\"\\nüìã Columns ({len(df.columns)}): {', '.join(df.columns.tolist())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Filtering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Before filtering: 951 maps\n",
            "\n",
            "‚úÖ After filtering: 950 maps\n",
            "\n",
            "üìà CCU range:\n",
            "  Baseline: 1 - 11760\n",
            "  Future (target): 4 - 7563\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>map_code</th>\n",
              "      <th>creator_followers</th>\n",
              "      <th>in_discovery</th>\n",
              "      <th>xp_enabled</th>\n",
              "      <th>num_tags</th>\n",
              "      <th>max_players</th>\n",
              "      <th>version</th>\n",
              "      <th>baseline_ccu</th>\n",
              "      <th>future_ccu_7d</th>\n",
              "      <th>trend_slope</th>\n",
              "      <th>recent_momentum</th>\n",
              "      <th>volatility</th>\n",
              "      <th>map_age_days</th>\n",
              "      <th>avg_session_length</th>\n",
              "      <th>retention_rate</th>\n",
              "      <th>favorites_count</th>\n",
              "      <th>recommendations_count</th>\n",
              "      <th>unique_players</th>\n",
              "      <th>total_plays</th>\n",
              "      <th>total_minutes_played</th>\n",
              "      <th>play_frequency</th>\n",
              "      <th>virality_score</th>\n",
              "      <th>engagement_per_player</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9228-8994-1362</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>425</td>\n",
              "      <td>97.580986</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>-0.161506</td>\n",
              "      <td>-31.180451</td>\n",
              "      <td>52.866465</td>\n",
              "      <td>0</td>\n",
              "      <td>31.675714</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>2373</td>\n",
              "      <td>2738</td>\n",
              "      <td>73685</td>\n",
              "      <td>1.153814</td>\n",
              "      <td>35</td>\n",
              "      <td>31.051412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2898-7886-8847</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>404</td>\n",
              "      <td>8934.507042</td>\n",
              "      <td>5875.549020</td>\n",
              "      <td>-15.770700</td>\n",
              "      <td>-1943.719298</td>\n",
              "      <td>4307.768295</td>\n",
              "      <td>0</td>\n",
              "      <td>32.867143</td>\n",
              "      <td>0</td>\n",
              "      <td>3157</td>\n",
              "      <td>2053</td>\n",
              "      <td>274599</td>\n",
              "      <td>393086</td>\n",
              "      <td>8533841</td>\n",
              "      <td>1.431491</td>\n",
              "      <td>5210</td>\n",
              "      <td>31.077466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3428-5975-3171</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "      <td>187.672535</td>\n",
              "      <td>121.941176</td>\n",
              "      <td>-0.122525</td>\n",
              "      <td>20.692043</td>\n",
              "      <td>164.953606</td>\n",
              "      <td>0</td>\n",
              "      <td>30.677143</td>\n",
              "      <td>0</td>\n",
              "      <td>87</td>\n",
              "      <td>4</td>\n",
              "      <td>4212</td>\n",
              "      <td>6592</td>\n",
              "      <td>113064</td>\n",
              "      <td>1.565052</td>\n",
              "      <td>91</td>\n",
              "      <td>26.843305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7340-5853-5689</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>90.500000</td>\n",
              "      <td>102.196078</td>\n",
              "      <td>-0.231812</td>\n",
              "      <td>-40.288534</td>\n",
              "      <td>36.455694</td>\n",
              "      <td>0</td>\n",
              "      <td>44.687143</td>\n",
              "      <td>0</td>\n",
              "      <td>124</td>\n",
              "      <td>30</td>\n",
              "      <td>3593</td>\n",
              "      <td>4396</td>\n",
              "      <td>146963</td>\n",
              "      <td>1.223490</td>\n",
              "      <td>154</td>\n",
              "      <td>40.902588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8398-4381-0561</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>96.447183</td>\n",
              "      <td>103.803922</td>\n",
              "      <td>-0.305097</td>\n",
              "      <td>-73.967419</td>\n",
              "      <td>74.470861</td>\n",
              "      <td>0</td>\n",
              "      <td>42.271429</td>\n",
              "      <td>0</td>\n",
              "      <td>82</td>\n",
              "      <td>88</td>\n",
              "      <td>2295</td>\n",
              "      <td>3509</td>\n",
              "      <td>99665</td>\n",
              "      <td>1.528976</td>\n",
              "      <td>170</td>\n",
              "      <td>43.427015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         map_code  creator_followers  in_discovery  xp_enabled  num_tags  \\\n",
              "0  9228-8994-1362                  0             0           0         3   \n",
              "1  2898-7886-8847                  0             0           0         4   \n",
              "2  3428-5975-3171                  0             0           0         4   \n",
              "3  7340-5853-5689                  0             0           0         4   \n",
              "4  8398-4381-0561                  0             0           0         4   \n",
              "\n",
              "   max_players  version  baseline_ccu  future_ccu_7d  trend_slope  \\\n",
              "0            0      425     97.580986      90.000000    -0.161506   \n",
              "1            0      404   8934.507042    5875.549020   -15.770700   \n",
              "2            0       59    187.672535     121.941176    -0.122525   \n",
              "3            0       63     90.500000     102.196078    -0.231812   \n",
              "4            0       38     96.447183     103.803922    -0.305097   \n",
              "\n",
              "   recent_momentum   volatility  map_age_days  avg_session_length  \\\n",
              "0       -31.180451    52.866465             0           31.675714   \n",
              "1     -1943.719298  4307.768295             0           32.867143   \n",
              "2        20.692043   164.953606             0           30.677143   \n",
              "3       -40.288534    36.455694             0           44.687143   \n",
              "4       -73.967419    74.470861             0           42.271429   \n",
              "\n",
              "   retention_rate  favorites_count  recommendations_count  unique_players  \\\n",
              "0               0               35                      0            2373   \n",
              "1               0             3157                   2053          274599   \n",
              "2               0               87                      4            4212   \n",
              "3               0              124                     30            3593   \n",
              "4               0               82                     88            2295   \n",
              "\n",
              "   total_plays  total_minutes_played  play_frequency  virality_score  \\\n",
              "0         2738                 73685        1.153814              35   \n",
              "1       393086               8533841        1.431491            5210   \n",
              "2         6592                113064        1.565052              91   \n",
              "3         4396                146963        1.223490             154   \n",
              "4         3509                 99665        1.528976             170   \n",
              "\n",
              "   engagement_per_player  \n",
              "0              31.051412  \n",
              "1              31.077466  \n",
              "2              26.843305  \n",
              "3              40.902588  \n",
              "4              43.427015  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f\"üìä Before filtering: {len(df)} maps\\n\")\n",
        "\n",
        "# Remove maps with insufficient data\n",
        "df = df[df['baseline_ccu'] > 0]\n",
        "df = df[df['future_ccu_7d'] > 0]\n",
        "\n",
        "print(f\"‚úÖ After filtering: {len(df)} maps\")\n",
        "print(f\"\\nüìà CCU range:\")\n",
        "print(f\"  Baseline: {df['baseline_ccu'].min():.0f} - {df['baseline_ccu'].max():.0f}\")\n",
        "print(f\"  Future (target): {df['future_ccu_7d'].min():.0f} - {df['future_ccu_7d'].max():.0f}\")\n",
        "\n",
        "# Show first few rows\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Models with Enhanced Features (20 total!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Features: 20\n",
            "‚úÖ Samples: 950\n",
            "\n",
            "üìã Feature List:\n",
            "      1. baseline_ccu\n",
            "      2. trend_slope\n",
            "      3. recent_momentum\n",
            "      4. volatility\n",
            "      5. map_age_days\n",
            "      6. in_discovery\n",
            "      7. creator_followers\n",
            "      8. xp_enabled\n",
            "      9. num_tags\n",
            "     10. max_players\n",
            "     11. version\n",
            "  üÜï 12. avg_session_length\n",
            "  üÜï 13. retention_rate\n",
            "  üÜï 14. favorites_count\n",
            "  üÜï 15. recommendations_count\n",
            "  üÜï 16. unique_players\n",
            "  üÜï 17. total_plays\n",
            "  üÜï 18. play_frequency\n",
            "  üÜï 19. virality_score\n",
            "  üÜï 20. engagement_per_player\n",
            "\n",
            "üìä Training set: 760 maps\n",
            "üìä Test set: 190 maps\n"
          ]
        }
      ],
      "source": [
        "# Define all 20 features\n",
        "feature_columns = [\n",
        "    # fncreate.gg features (11)\n",
        "    'baseline_ccu', 'trend_slope', 'recent_momentum', 'volatility',\n",
        "    'map_age_days', 'in_discovery', 'creator_followers', 'xp_enabled',\n",
        "    'num_tags', 'max_players', 'version',\n",
        "    # Fortnite API features (9 NEW!)\n",
        "    'avg_session_length', 'retention_rate', 'favorites_count',\n",
        "    'recommendations_count', 'unique_players', 'total_plays',\n",
        "    'play_frequency', 'virality_score', 'engagement_per_player'\n",
        "]\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df['future_ccu_7d']\n",
        "\n",
        "print(f\"‚úÖ Features: {X.shape[1]}\")\n",
        "print(f\"‚úÖ Samples: {X.shape[0]}\")\n",
        "print(f\"\\nüìã Feature List:\")\n",
        "for i, col in enumerate(feature_columns, 1):\n",
        "    marker = \"üÜï\" if i > 11 else \"  \"\n",
        "    print(f\"  {marker} {i:2d}. {col}\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Training set: {X_train.shape[0]} maps\")\n",
        "print(f\"üìä Test set: {X_test.shape[0]} maps\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Training models...\n",
            "\n",
            "Training Random Forest...\n",
            "  R¬≤ Score: 0.7546\n",
            "  MAE: 90.97 CCU\n",
            "  RMSE: 444.17 CCU\n",
            "\n",
            "Training Gradient Boosting...\n",
            "  R¬≤ Score: 0.7677\n",
            "  MAE: 92.45 CCU\n",
            "  RMSE: 432.13 CCU\n",
            "\n",
            "Training Linear Regression...\n",
            "  R¬≤ Score: 0.8008\n",
            "  MAE: 78.58 CCU\n",
            "  RMSE: 400.14 CCU\n",
            "\n",
            "‚úÖ All models trained!\n"
          ]
        }
      ],
      "source": [
        "# Train 3 models\n",
        "models = {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    'Linear Regression': LinearRegression()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"üöÄ Training models...\\n\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    # Metrics\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    \n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'r2': r2,\n",
        "        'mae': mae,\n",
        "        'rmse': rmse\n",
        "    }\n",
        "    \n",
        "    print(f\"  R¬≤ Score: {r2:.4f}\")\n",
        "    print(f\"  MAE: {mae:.2f} CCU\")\n",
        "    print(f\"  RMSE: {rmse:.2f} CCU\\n\")\n",
        "\n",
        "print(\"‚úÖ All models trained!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Compare Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÜ Model Comparison:\n",
            "            Model  R¬≤ Score  MAE (CCU)  RMSE (CCU)\n",
            "Linear Regression  0.800803  78.577983  400.140230\n",
            "Gradient Boosting  0.767677  92.453631  432.132738\n",
            "    Random Forest  0.754559  90.974508  444.165135\n",
            "\n",
            "ü•á Best Model: Linear Regression\n",
            "   R¬≤ Score: 0.8008\n",
            "   MAE: 78.58 CCU\n",
            "   RMSE: 400.14 CCU\n",
            "\n",
            "üìà Improvement from old model (R¬≤ = 0.76):\n",
            "   R¬≤ improved by: +5.4%\n"
          ]
        }
      ],
      "source": [
        "# Comparison table\n",
        "comparison = pd.DataFrame({\n",
        "    'Model': list(results.keys()),\n",
        "    'R¬≤ Score': [r['r2'] for r in results.values()],\n",
        "    'MAE (CCU)': [r['mae'] for r in results.values()],\n",
        "    'RMSE (CCU)': [r['rmse'] for r in results.values()]\n",
        "}).sort_values('R¬≤ Score', ascending=False)\n",
        "\n",
        "print(\"üèÜ Model Comparison:\")\n",
        "print(comparison.to_string(index=False))\n",
        "\n",
        "# Best model\n",
        "best_model_name = comparison.iloc[0]['Model']\n",
        "best_model = results[best_model_name]['model']\n",
        "\n",
        "print(f\"\\nü•á Best Model: {best_model_name}\")\n",
        "print(f\"   R¬≤ Score: {comparison.iloc[0]['R¬≤ Score']:.4f}\")\n",
        "print(f\"   MAE: {comparison.iloc[0]['MAE (CCU)']:.2f} CCU\")\n",
        "print(f\"   RMSE: {comparison.iloc[0]['RMSE (CCU)']:.2f} CCU\")\n",
        "\n",
        "# Compare with old model (R¬≤ = 0.76)\n",
        "print(f\"\\nüìà Improvement from old model (R¬≤ = 0.76):\")\n",
        "old_r2 = 0.76\n",
        "new_r2 = comparison.iloc[0]['R¬≤ Score']\n",
        "improvement = ((new_r2 - old_r2) / old_r2) * 100\n",
        "print(f\"   R¬≤ improved by: {improvement:+.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Enhanced Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model saved: ../data/models/enhanced_future_ccu_predictor.pkl\n",
            "‚úÖ Metadata saved: ../data/models/enhanced_future_ccu_predictor_metadata.json\n",
            "\n",
            "üéâ Enhanced model training complete!\n",
            "\n",
            "üìä Final Results:\n",
            "   Model: Linear Regression\n",
            "   R¬≤ Score: 0.8008\n",
            "   MAE: 78.58 CCU\n",
            "   Features: 20 (11 fncreate + 9 Fortnite API)\n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "model_path = MODEL_DIR / 'enhanced_future_ccu_predictor.pkl'\n",
        "joblib.dump(best_model, model_path)\n",
        "print(f\"‚úÖ Model saved: {model_path}\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    'model_type': best_model_name,\n",
        "    'features': feature_columns,\n",
        "    'num_features': len(feature_columns),\n",
        "    'fncreate_features': 11,\n",
        "    'fortnite_api_features': 9,\n",
        "    'r2_score': float(results[best_model_name]['r2']),\n",
        "    'mae': float(results[best_model_name]['mae']),\n",
        "    'rmse': float(results[best_model_name]['rmse']),\n",
        "    'training_samples': len(X_train),\n",
        "    'test_samples': len(X_test),\n",
        "    'trained_at': datetime.now().isoformat(),\n",
        "    'data_sources': ['fncreate.gg', 'fortnite_ecosystem_api']\n",
        "}\n",
        "\n",
        "metadata_path = MODEL_DIR / 'enhanced_future_ccu_predictor_metadata.json'\n",
        "with open(metadata_path, 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Metadata saved: {metadata_path}\")\n",
        "print(f\"\\nüéâ Enhanced model training complete!\")\n",
        "print(f\"\\nüìä Final Results:\")\n",
        "print(f\"   Model: {best_model_name}\")\n",
        "print(f\"   R¬≤ Score: {metadata['r2_score']:.4f}\")\n",
        "print(f\"   MAE: {metadata['mae']:.2f} CCU\")\n",
        "print(f\"   Features: {metadata['num_features']} ({metadata['fncreate_features']} fncreate + {metadata['fortnite_api_features']} Fortnite API)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
